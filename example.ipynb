{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HudsonHuang/mixbatch/blob/master/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRqz_VQiipo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# from  matplotlib import pyplot as plt\n",
        "np.random.seed(6) #随机数，这样做的目的是在每次运行程序时，初始值保持一致。seed的值可以随便设置。\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Dropout ,Activation, Flatten\n",
        "from keras.layers import Conv2D ,MaxPooling2D   #卷积层，池化层\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "import keras.backend.tensorflow_backend as KTF\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.layers import Layer\n",
        "np.random.seed(2019)\n",
        "tf.set_random_seed(2019)\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True  # 不全部占满显存, 按需分配\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "KTF.set_session(sess)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne7lberGjVSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class MixBatch(Layer):\n",
        "    def __init__(self,batch_size, alpha=0.2, **kwargs) -> None:\n",
        "        self.alpha = alpha\n",
        "        self.batch_size = batch_size\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def get_beta(self,input_shape):\n",
        "        beta_shape = [1] * len(list(input_shape))\n",
        "        beta_shape[0] = self.batch_size\n",
        "        return tf.distributions.Beta(self.alpha, self.alpha).sample(beta_shape)\n",
        "\n",
        "    def mixup_tf(self, features):\n",
        "        # do mixup here\n",
        "        # tensorflow version\n",
        "        print(\"features\",features.shape)\n",
        "        input_shape = K.int_shape(features)\n",
        "        mix = self.get_beta(features.shape)\n",
        "        mix = tf.maximum(mix, 1 - mix)  # contrl to let data close to x1\n",
        "        features = features * mix + features[::-1] * (1 - mix)\n",
        "        return features\n",
        "\n",
        "    def call(self, x,training=None, **kwargs):\n",
        "        if training:\n",
        "            return self.mixup_tf(x)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'alpha': self.alpha,\n",
        "        }\n",
        "        base_config = super().get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwWlE4khitTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_default_callbacks(log_dir=None,comment=''):\n",
        "    import time\n",
        "    import os\n",
        "\n",
        "    if log_dir==None:\n",
        "        def _get_current_date():\n",
        "            strDate = time.strftime('%Y%m%d_%H%M%S',\n",
        "                                    time.localtime(time.time())) \n",
        "            return strDate\n",
        "        log_dir = os.path.join('./',_get_current_date()+comment)\n",
        "\n",
        "    cb = []\n",
        "    weight_path = os.path.join(log_dir, 'model.h5')\n",
        "    ckpt_cb = keras.callbacks.ModelCheckpoint(weight_path,\n",
        "                                            save_weights_only=True,\n",
        "                                            save_best_only=True)\n",
        "    cb.append(ckpt_cb)\n",
        "\n",
        "    tb_cb = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "    cb.append(tb_cb)\n",
        "\n",
        "    # nan_cb = keras.callbacks.TerminateOnNaN()\n",
        "    # cb.append(nan_cb)\n",
        "\n",
        "    # update_pruning = sparsity.UpdatePruningStep(),\n",
        "    # pruning_summary = ssparsity.PruningSummaries(log_dir=log_dir, profile_batch=0)\n",
        "    # cb.append(update_pruning)\n",
        "    # cb.append(pruning_summary)\n",
        "    return cb\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FksyuaKZivub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "81b3b50e-bb63-4e62-a0e6-06d002c8355d"
      },
      "source": [
        "\n",
        "(X_train,y_train),(X_test,y_test)=mnist.load_data()   #导入mnist数据\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "#这里大家可能不是很了解，主要是为了把mnist数据变成二维图片形式\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255     #做标准化（0，1）之间 ，深度学习对样本值敏感需要做标准化处理\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "#把标签值变成一维数组显示，例如 标签1 ——0100000000"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atJ59qKiixJT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "e8a6deb9-c32c-45c7-9f04-828620e9d198"
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(MixBatch(batch_size=32))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                   activation='relu',\n",
        "                   input_shape=(28,28,1)))\n",
        "model.add(MixBatch(batch_size=32))\n",
        "#第一层卷积层，32个特征图，每个特征图中的神经元与输入中的3×3的领域相连。参数可调\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))   #第二层卷积层,64个特征图。参数可调\n",
        "model.add(MixBatch(batch_size=32))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))   #池化层 2×2做映射，参数可调\n",
        "model.add(MixBatch(batch_size=32))\n",
        "model.add(Dropout(0.25))   #Dropou算法用于测试集的精确度的优化，这个也可以换。\n",
        "model.add(Flatten())    #把二维数组拉成一维\n",
        "model.add(Dense(128, activation='relu'))    #正常的神经网络层\n",
        "model.add(MixBatch(batch_size=32))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax')) #输出层\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                         optimizer='adam',\n",
        "                          metrics=['accuracy'])   #交叉熵，训练优化算法adam\n",
        "cb = get_default_callbacks(comment=\"MBall\")\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1,callbacks=cb,validation_data=(X_test, Y_test))  # batch=32,epoch=10,参数可调，总迭代次数大家会算吗？\n",
        "# score = model.evaluate(, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0716 02:12:45.124864 139682443163520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0716 02:12:45.129883 139682443163520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "W0716 02:12:47.662666 139682443163520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0716 02:12:47.671231 139682443163520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0716 02:12:47.719000 139682443163520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0716 02:12:47.723762 139682443163520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0716 02:12:47.737112 139682443163520 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0716 02:12:47.823356 139682443163520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0716 02:12:47.961135 139682443163520 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0716 02:12:50.373660 139682443163520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "W0716 02:12:50.375442 139682443163520 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "59232/60000 [============================>.] - ETA: 0s - loss: 0.1990 - acc: 0.9390"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}